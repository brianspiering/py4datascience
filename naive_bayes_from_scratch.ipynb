{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Implement-Naive-Bayes-From-Scratch\" data-toc-modified-id=\"Implement-Naive-Bayes-From-Scratch-1\">Implement Naive Bayes From Scratch</a></span></li><li><span><a href=\"#Bayes'-Theorem\" data-toc-modified-id=\"Bayes'-Theorem-2\">Bayes' Theorem</a></span></li><li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes-3\">Learning Outcomes</a></span></li><li><span><a href=\"#A-Recipe-for-Naive-Bayes-Classification\" data-toc-modified-id=\"A-Recipe-for-Naive-Bayes-Classification-4\">A Recipe for Naive Bayes Classification</a></span></li><li><span><a href=\"#Acquire-data-&amp;-preprocess\" data-toc-modified-id=\"Acquire-data-&amp;-preprocess-5\">Acquire data &amp; preprocess</a></span></li><li><span><a href=\"#Calculate-document-class-priors\" data-toc-modified-id=\"Calculate-document-class-priors-6\">Calculate document class priors</a></span></li><li><span><a href=\"#Calculate-conditional-probabilities-of-each-word-for-each-class\" data-toc-modified-id=\"Calculate-conditional-probabilities-of-each-word-for-each-class-7\">Calculate conditional probabilities of each word for each class</a></span></li><li><span><a href=\"#Given-a-new-document-without-a-label,--calculate-the-proportional-probabilities-for-each-class\" data-toc-modified-id=\"Given-a-new-document-without-a-label,--calculate-the-proportional-probabilities-for-each-class-8\">Given a new document without a label,  calculate the proportional probabilities for each class</a></span></li><li><span><a href=\"#Pick-the-winning-class\" data-toc-modified-id=\"Pick-the-winning-class-9\">Pick the winning class</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-10\">Summary</a></span></li><li><span><a href=\"#Bonus-Material\" data-toc-modified-id=\"Bonus-Material-11\">Bonus Material</a></span></li><li><span><a href=\"#Further-Study\" data-toc-modified-id=\"Further-Study-12\">Further Study</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Naive Bayes From Scratch\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' Theorem\n",
    "------\n",
    "\n",
    "$$ P(A | B) = \\frac{P(B|A)P(A)}{P(B) $$\n",
    "\n",
    "![](images/bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Outcomes\n",
    "------\n",
    "\n",
    "__By The End Of This Notebook You Should Be Able To:__\n",
    "\n",
    "1. Write idiomatic Python to model data. \n",
    "1. Implement Naive Bayes in pure Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "A Recipe for Naive Bayes Classification\n",
    "-------\n",
    "\n",
    "1. Acquire labeled training data\n",
    "1. With training data:\n",
    "    1. Calculate document class priors\n",
    "    1. Calculate conditional probabilities of each word for each class\n",
    "1. With new data:\n",
    "    1. Calculate the proportional probabilities for each class of new document\n",
    "    1. Pick the winning class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Let's make a data class to hold our data\n",
    "data = LabeledTextData(id_num=42, label='cat', words=\"🐱 🐱 🐈 🐶\".split())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledTextData:\n",
    "    def __init__(self, id_num, label, words):\n",
    "        self.id_num = id_num\n",
    "        self.label = label \n",
    "        self.words = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LabeledTextData(id_num=42, label='cat', words=\"🐱 🐱 🐈 🐶\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `LabeledTextData` class is mostly data. We can use `dataclass` (new to Python 3.7) to simplify our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LabeledTextData:\n",
    "    id_num: int\n",
    "    label: str\n",
    "    words: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [LabeledTextData(42, 'cat',  \"🐈 🐯 🐱 🐩 🐱\".split()),\n",
    "         LabeledTextData(43, 'dog',  \"🐶 🐶 🐈 🐶 🐩 🐈 🐶 🐶\".split()),\n",
    "         LabeledTextData(45, 'cat',  \"🐈 🐈 🐯 🐶 🐈\".split()),\n",
    "         LabeledTextData(45, 'cat',  \"🐈 🐈 🐈\".split()),\n",
    "         LabeledTextData(48, 'dog',  \"🐶 🐶 🐯 🐈 🐩 🐱 🐩 🐶 🐩 🐶 \".split()),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate document class priors\n",
    "---- \n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "labels = {doc.label for doc in train}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(train)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.6)\n",
      "('dog', 0.4)\n"
     ]
    }
   ],
   "source": [
    "# For each label, find the probability of baseline occurance\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Find the count of each category\n",
    "for doc in train:\n",
    "    class_counts[doc.label] += 1\n",
    "\n",
    "# Convert them to probabilities\n",
    "doc_priors = {label: count/n_docs for label, count in class_counts.items()}\n",
    "    \n",
    "print(*doc_priors.items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities of each word for each class\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['🐈', '🐯', '🐱', '🐩', '🐱', '🐶', '🐶', '🐈', '🐶', '🐩', '🐈', '🐶', '🐶', '🐈', '🐈', '🐯', '🐶', '🐈', '🐈', '🐈', '🐈', '🐶', '🐶', '🐯', '🐈', '🐩', '🐱', '🐩', '🐶', '🐩', '🐶']\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "vocab = []\n",
    "\n",
    "for doc in train:\n",
    "    vocab.extend(doc.words)\n",
    "    \n",
    "print(\"Vocab:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'🐈', '🐩', '🐯', '🐱', '🐶'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tokens\n",
    "set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality of vocab: 5\n"
     ]
    }
   ],
   "source": [
    "# Number of unique tokens, aka cardinality\n",
    "v = len(set(vocab))\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'cat': defaultdict(float,\n",
       "                         {'🐈': 0.5384615384615384,\n",
       "                          '🐯': 0.15384615384615385,\n",
       "                          '🐱': 0.15384615384615385,\n",
       "                          '🐩': 0.07692307692307693,\n",
       "                          '🐶': 0.07692307692307693}),\n",
       "             'dog': defaultdict(float,\n",
       "                         {'🐈': 0.16666666666666666,\n",
       "                          '🐯': 0.05555555555555555,\n",
       "                          '🐱': 0.05555555555555555,\n",
       "                          '🐩': 0.2222222222222222,\n",
       "                          '🐶': 0.5})})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A default dict of default dicts; inner default dict is probability\n",
    "cond_prob = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    label_words = []\n",
    "    for doc in train:\n",
    "         # For a given label, get a list of all the tokens for all the docs \n",
    "        if doc.label == label:\n",
    "            label_words.extend(doc.words)\n",
    "\n",
    "    for word in vocab:\n",
    "        # Find conditional probability: word count / total count\n",
    "        cond_prob[label][word] = label_words.count(word) / len(label_words) \n",
    "\n",
    "cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that each label is a probability mass function (pmf). A pmf sums to 1\n",
    "from math import isclose\n",
    "\n",
    "for label in labels:\n",
    "    assert isclose(sum(cond_prob[label].values()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new document without a label,  calculate the proportional probabilities for each class\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c | X) = P(c) •  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.0)\n",
      "('dog', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# test = LabeledTextData(id_num=90, label=None, words=\"🐱\".split())\n",
    "# test = LabeledTextData(id_num=91, label=None, words=\"🐶 🐶\".split()) \n",
    "# test = LabeledTextData(id_num=92, label=None, words=\"🐶 🐱\".split())\n",
    "# test = LabeledTextData(id_num=93, label=None, words=\"🐈 🐈 🐶 🐶 🐩 🐱 🐱\".split())\n",
    "# test = LabeledTextData(id_num=94, label=None, words=\"🐬 \".split()) # Out of sample prediction\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    # For each label, calculate the conditional probability based on the prior and the tokens that appear\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in test.words)\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the winning class\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: cat\n"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(\"The predicted class is: \", end=\"\")\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for Improvement\n",
    "-----\n",
    "\n",
    "1. Switch from human-readable data class to matrix storage\n",
    "    - Simpler\n",
    "    - Faster (vectorized operations and fewer passes through the data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Naive Bayes (NB) is a simple and powerful algorithm for text classification\n",
    "- To apply NB, follow a step-by-step process to calculate each probability\n",
    "- Python's Standard Library has functions to write elegant and performant code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Material\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/bayesian_evol.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Study\n",
    "------\n",
    "\n",
    "- [Data Science Handbook on Naive Bayes](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)\n",
    "- https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/\n",
    "- http://www.statsoft.com/textbook/naive-bayes-classifier (sorry about the blue front)\n",
    "- Read [Text classification and Naive Bayes](https://web.stanford.edu/class/cs124/lec/naivebayes.pdf)   \n",
    "- Read [Naive Bayes blogpost](http://sebastianraschka.com/Articles/2014_naive_bayes_1.html)\n",
    "- https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/modified_bayes_theorem.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
