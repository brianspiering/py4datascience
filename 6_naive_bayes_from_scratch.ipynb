{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Implement-Naive-Bayes-From-Scratch\" data-toc-modified-id=\"Implement-Naive-Bayes-From-Scratch-1\">Implement Naive Bayes From Scratch</a></span></li><li><span><a href=\"#Bayes'-Theorem\" data-toc-modified-id=\"Bayes'-Theorem-2\">Bayes' Theorem</a></span></li><li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes-3\">Learning Outcomes</a></span></li><li><span><a href=\"#A-Recipe-for-Naive-Bayes-Classification\" data-toc-modified-id=\"A-Recipe-for-Naive-Bayes-Classification-4\">A Recipe for Naive Bayes Classification</a></span></li><li><span><a href=\"#Acquire-data-&amp;-preprocess\" data-toc-modified-id=\"Acquire-data-&amp;-preprocess-5\">Acquire data &amp; preprocess</a></span></li><li><span><a href=\"#Instantiation\" data-toc-modified-id=\"Instantiation-6\">Instantiation</a></span></li><li><span><a href=\"#self\" data-toc-modified-id=\"self-7\"><code>self</code></a></span></li><li><span><a href=\"#What-the-heck-is-@dataclass?\" data-toc-modified-id=\"What-the-heck-is-@dataclass?-8\">What the heck is <code>@dataclass</code>?</a></span></li><li><span><a href=\"#Dataclassess-make-class-easier-to-write\" data-toc-modified-id=\"Dataclassess-make-class-easier-to-write-9\">Dataclassess make class easier to write</a></span></li><li><span><a href=\"#Data-classes-allow-for-more-human-readable-code\" data-toc-modified-id=\"Data-classes-allow-for-more-human-readable-code-10\">Data classes allow for more human-readable code</a></span></li><li><span><a href=\"#Calculate-document-class-priors\" data-toc-modified-id=\"Calculate-document-class-priors-11\">Calculate document class priors</a></span></li><li><span><a href=\"#Calculate-conditional-probabilities-of-each-word-for-each-class\" data-toc-modified-id=\"Calculate-conditional-probabilities-of-each-word-for-each-class-12\">Calculate conditional probabilities of each word for each class</a></span></li><li><span><a href=\"#Given-a-new-document-without-a-label,--calculate-the-proportional-probabilities-for-each-class\" data-toc-modified-id=\"Given-a-new-document-without-a-label,--calculate-the-proportional-probabilities-for-each-class-13\">Given a new document without a label,  calculate the proportional probabilities for each class</a></span></li><li><span><a href=\"#Pick-the-winning-class\" data-toc-modified-id=\"Pick-the-winning-class-14\">Pick the winning class</a></span></li><li><span><a href=\"#Ideas-for-Improvement\" data-toc-modified-id=\"Ideas-for-Improvement-15\">Ideas for Improvement</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-16\">Summary</a></span></li><li><span><a href=\"#Bonus-Material\" data-toc-modified-id=\"Bonus-Material-17\">Bonus Material</a></span></li><li><span><a href=\"#Further-Study\" data-toc-modified-id=\"Further-Study-18\">Further Study</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Naive Bayes From Scratch\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' Theorem\n",
    "------\n",
    "\n",
    "$$ P(A | B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "\n",
    "![](images/bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Outcomes\n",
    "------\n",
    "\n",
    "__By The End Of This Notebook You Should Be Able To:__\n",
    "\n",
    "1. Write idiomatic Python to model data. \n",
    "1. Implement Naive Bayes in pure Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "A Recipe for Naive Bayes Classification\n",
    "-------\n",
    "\n",
    "1. Acquire labeled training data\n",
    "1. With training data:\n",
    "    1. Calculate document class priors\n",
    "    1. Calculate conditional probabilities of each word for each class\n",
    "1. With new data:\n",
    "    1. Calculate the proportional probabilities for each class of new document\n",
    "    1. Pick the winning class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Let's make a data class to hold our data\n",
    "data = LabeledTextData(id_num=42, label='cat', words=\"ğŸ± ğŸ± ğŸˆ ğŸ¶\".split())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledTextData:\n",
    "    def __init__(self, id_num, label, words):\n",
    "        self.id_num = id_num\n",
    "        self.label = label \n",
    "        self.words = words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiation\n",
    "----\n",
    "\n",
    "Instantiation is the process of creating instances from classes.\n",
    "\n",
    "`def __init__` is how that happens in Python.\n",
    "\n",
    "__init__ is short for initialize.\n",
    "\n",
    "`def __init__` is the __constructor__ that makes guarantees during initialization. Every instance of this class will have these attributes by default.\n",
    "\n",
    "`self`\n",
    "------\n",
    "\n",
    "`self` refers to the specific instance (think of it as \"this particular one\")\n",
    "\n",
    "Use self.data to access classâ€™s data member.\n",
    "\n",
    "`self` is kinda silly but I'll show you a trick later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LabeledTextData(id_num=42, label='cat', words=\"ğŸ± ğŸ± ğŸˆ ğŸ¶\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `LabeledTextData` class is mostly data. We can use `dataclass` (new to Python 3.7) to simplify our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LabeledTextData:\n",
    "    id_num: int\n",
    "    label: str\n",
    "    words: list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the heck is `@dataclass`?\n",
    "----\n",
    "\n",
    "`@` symbol on a function or class is a called decorator.\n",
    "\n",
    "You can think of decorator like a hat that gives the function or class super powers.\n",
    "\n",
    "We might discuss decorators in more detail later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataclassess make class easier to write\n",
    "--------\n",
    "\n",
    "Dataclasses reduces boilerplate code, boilerplate code is code that you have to write but does add unique value.\n",
    "\n",
    "You don't need to write out explicit `self` on every line and you don't need `__int__â€¦`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data classes allow for more human-readable code\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LabeledTextData(42, 'cat',  \"ğŸˆ ğŸ¯ ğŸ± ğŸ© ğŸ±\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data classes allow for . (dot) access\n",
    "data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thus fluent interface with custom classes\n",
    "data.label.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [LabeledTextData(42, 'cat',  \"ğŸˆ ğŸ¯ ğŸ± ğŸ© ğŸ±\".split()),\n",
    "         LabeledTextData(43, 'dog',  \"ğŸ¶ ğŸ¶ ğŸˆ ğŸ¶ ğŸ© ğŸˆ ğŸ¶ ğŸ¶\".split()),\n",
    "         LabeledTextData(45, 'cat',  \"ğŸˆ ğŸˆ ğŸ¯ ğŸ¶ ğŸˆ\".split()),\n",
    "         LabeledTextData(45, 'cat',  \"ğŸˆ ğŸˆ ğŸˆ\".split()),\n",
    "         LabeledTextData(48, 'dog',  \"ğŸ¶ ğŸ¶ ğŸ¯ ğŸˆ ğŸ© ğŸ± ğŸ© ğŸ¶ ğŸ© ğŸ¶ \".split()),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate document class priors\n",
    "---- \n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "labels = {doc.label for doc in train}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(train)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat', 0.6)\n",
      "('dog', 0.4)\n"
     ]
    }
   ],
   "source": [
    "# For each label, find the probability of baseline occurance\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Find the count of each category\n",
    "for doc in train:\n",
    "    class_counts[doc.label] += 1\n",
    "\n",
    "# Convert them to probabilities\n",
    "doc_priors = {label: count/n_docs for label, count in class_counts.items()}\n",
    "    \n",
    "print(*doc_priors.items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities of each word for each class\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['ğŸˆ', 'ğŸ¯', 'ğŸ±', 'ğŸ©', 'ğŸ±', 'ğŸ¶', 'ğŸ¶', 'ğŸˆ', 'ğŸ¶', 'ğŸ©', 'ğŸˆ', 'ğŸ¶', 'ğŸ¶', 'ğŸˆ', 'ğŸˆ', 'ğŸ¯', 'ğŸ¶', 'ğŸˆ', 'ğŸˆ', 'ğŸˆ', 'ğŸˆ', 'ğŸ¶', 'ğŸ¶', 'ğŸ¯', 'ğŸˆ', 'ğŸ©', 'ğŸ±', 'ğŸ©', 'ğŸ¶', 'ğŸ©', 'ğŸ¶']\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "vocab = []\n",
    "\n",
    "for doc in train:\n",
    "    vocab.extend(doc.words)\n",
    "    \n",
    "print(\"Vocab:\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ğŸˆ', 'ğŸ©', 'ğŸ¯', 'ğŸ±', 'ğŸ¶'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique tokens\n",
    "set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality of vocab: 5\n"
     ]
    }
   ],
   "source": [
    "# Number of unique tokens, aka cardinality\n",
    "v = len(set(vocab))\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'dog': defaultdict(float,\n",
       "                         {'ğŸˆ': 0.16666666666666666,\n",
       "                          'ğŸ¯': 0.05555555555555555,\n",
       "                          'ğŸ±': 0.05555555555555555,\n",
       "                          'ğŸ©': 0.2222222222222222,\n",
       "                          'ğŸ¶': 0.5}),\n",
       "             'cat': defaultdict(float,\n",
       "                         {'ğŸˆ': 0.5384615384615384,\n",
       "                          'ğŸ¯': 0.15384615384615385,\n",
       "                          'ğŸ±': 0.15384615384615385,\n",
       "                          'ğŸ©': 0.07692307692307693,\n",
       "                          'ğŸ¶': 0.07692307692307693})})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A default dict of default dicts; inner default dict is probability\n",
    "cond_prob = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in labels:\n",
    "    \n",
    "    label_words = []\n",
    "    for doc in train:\n",
    "         # For a given label, get a list of all the tokens for all the docs \n",
    "        if doc.label == label:\n",
    "            label_words.extend(doc.words)\n",
    "\n",
    "    for word in vocab:\n",
    "        # Find conditional probability: word count / total count\n",
    "        cond_prob[label][word] = label_words.count(word) / len(label_words) \n",
    "\n",
    "cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that each label is a probability mass function (pmf). A pmf sums to 1\n",
    "from math import isclose\n",
    "\n",
    "for label in labels:\n",
    "    assert isclose(sum(cond_prob[label].values()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new document without a label,  calculate the proportional probabilities for each class\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c | X) = P(c) â€¢  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-becf9349b8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# For each label, calculate the conditional probability based on the prior and the tokens that appear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprob_predicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# test = LabeledTextData(id_num=90, label=None, words=\"ğŸ±\".split())\n",
    "# test = LabeledTextData(id_num=91, label=None, words=\"ğŸ¶ ğŸ¶\".split()) \n",
    "# test = LabeledTextData(id_num=92, label=None, words=\"ğŸ¶ ğŸ±\".split())\n",
    "# test = LabeledTextData(id_num=93, label=None, words=\"ğŸˆ ğŸˆ ğŸ¶ ğŸ¶ ğŸ© ğŸ± ğŸ±\".split())\n",
    "# test = LabeledTextData(id_num=94, label=None, words=\"ğŸ¬ \".split()) # Out of sample prediction\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    # For each label, calculate the conditional probability based on the prior and the tokens that appear\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in test.words)\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the winning class\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itemgetter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6d1d756971cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Handle ties and fall back to document priors if winning probability is zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m label, prob = max(prob_predicted.items(),\n\u001b[0;32m----> 3\u001b[0;31m                   key=itemgetter(1))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The predicted class is: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itemgetter' is not defined"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(\"The predicted class is: \", end=\"\")\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(\"The predicted class is:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for Improvement\n",
    "-----\n",
    "\n",
    "1. Switch from human-readable data class to matrix\n",
    "    - Matrix would allow our code to be simpler\n",
    "    - Faster (vectorized operations and fewer passes through the data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Naive Bayes (NB) is a simple and powerful algorithm for text classification\n",
    "- To apply NB, follow a step-by-step process to calculate each probability\n",
    "- Python's Standard Library has functions to write elegant and performant code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Material\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/bayesian_evol.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Study\n",
    "------\n",
    "\n",
    "- [Data Science Handbook on Naive Bayes](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html)\n",
    "- https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/\n",
    "- http://www.statsoft.com/textbook/naive-bayes-classifier (sorry about the blue front)\n",
    "- Read [Text classification and Naive Bayes](https://web.stanford.edu/class/cs124/lec/naivebayes.pdf)   \n",
    "- Read [Naive Bayes blogpost](http://sebastianraschka.com/Articles/2014_naive_bayes_1.html)\n",
    "- https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"https://imgs.xkcd.com/comics/modified_bayes_theorem.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
